import argparse
import logging
import json
import pandas as pd
from ._loaddata import load_data
from ._pickism import entropy_analysis, pick_ISM_spots, annotate_ISM, ISM_disambiguation
from ._entropy_time_series_anlysis import entropy_time_series_analysis
from ._analyzeism import ISM_analysis
from ._visualization import ISM_visualization, ISM_plot
from .build_ism import build_ISM
from ._abundancetable import region_pca_plot

logging.basicConfig(format='%(asctime)s - %(message)s', datefmt='%d-%b-%y %H:%M:%S', level=logging.INFO)

def main():
    
    parser = argparse.ArgumentParser(description='Informative Subtype Marker (ISM) is an efficient framework for genetic subtyping of a pandemic virus and implement it for SARS-CoV-2, the novel coronavirus that causes COVID-19.', prog='ncov_ism')
    subparsers = parser.add_subparsers(title='subcommands',
                                       description='the following subcommands \
                                    are available: build, analyze, visualize, default, ents, compress', 
                                    dest='subparser_name')
    # build
    build_parser = subparsers.add_parser("build")
    build_parser.add_argument("-i", metavar="input",
                        help="Multiple sequence alignment results in fasta format",
                        required=True, type=str)
    build_parser.add_argument("-m", metavar="metadata",
                        help="Metadata in tsv format",
                        required=True, type=str)
    build_parser.add_argument("-gb", metavar="genbank",
                        help="genbank file for reference sequence",
                        required=True, type=str)
    build_parser.add_argument("-o", metavar="output",
                        help="Path to the output directory",
                        required=True, type=str)
    build_parser.add_argument("-r", metavar="referenceId", help="accession number of the reference sequence", 
                        default='EPI_ISL_402125', required=False, type=str)
    build_parser.add_argument("-e", metavar="entropy", help="entropy threshold", 
                        default=0.2, required=False, type=float)
    build_parser.add_argument("-n", metavar="nullFreq", help="null frequency threshold", 
                        default=0.25, required=False, type=float)
    # analyze
    analyze_parser = subparsers.add_parser("analyze")
    analyze_parser.add_argument("-i", metavar="input",
                        help="Path to ISM_df file built from 'ncov_ism build' command",
                        required=True, type=str)
    analyze_parser.add_argument("-o", metavar="output",
                        help="Path to the output directory",
                        required=True, type=str)
    # visualization
    visualize_parser = subparsers.add_parser("visualize")
    visualize_parser.add_argument("-i", metavar="input",
                        help="Path to the directory containing ISM table and json files generated by ncov_ism analyze command",
                        required=True, type=str)
    visualize_parser.add_argument("-o", metavar="output",
                        help="Path to the output directory",
                        required=True, type=str)
    visualize_parser.add_argument("-sd", metavar="sampling-depth",
                        help="minimum number of sequences per country to be included in PCA analysis of ISM abundance table",
                        required=False, default=150, type=int)
    # default
    default_parser = subparsers.add_parser("default")
    default_parser.add_argument("-i", metavar="input",
                        help="Multiple sequence alignment results in fasta format",
                        required=True, type=str)
    default_parser.add_argument("-m", metavar="metadata",
                        help="Metadata in tsv format",
                        required=True, type=str)
    default_parser.add_argument("-o", metavar="output",
                        help="Path to the output directory",
                        required=True, type=str)
    # ents
    ents_parser = subparsers.add_parser("ents")
    ents_parser.add_argument("-i", metavar="input",
                        help="Multiple sequence alignment results in fasta format",
                        required=True, type=str)
    ents_parser.add_argument("-r", metavar="referenceId", 
                             help="accession number of the reference sequence", 
                             default='EPI_ISL_402125', required=False, type=str)
    ents_parser.add_argument("-o", metavar="output",
                        help="Path to the output directory",
                        required=True, type=str)
    # compress
    compress_parser = subparsers.add_parser("compress")
    compress_parser.add_argument("-i", metavar="input",
                                 help="Path to ISM_df file built by 'ncov_ism build' command",
                                 required=True, type=str)
    compress_parser.add_argument("-a", metavar="annotation", 
                                 help="Path to annotation file built by 'ncov_ism build' command", 
                                 required=True, type=str)
    compress_parser.add_argument("-p", metavar="position", 
                                 help="Path to a comma separated file containing compressed positions", 
                                 required=True, type=str)
    compress_parser.add_argument("-o", metavar="output",
                                 help="Path to the output directory",
                                 required=True, type=str)
    args = parser.parse_args()
    if args.subparser_name == "build":
        MSA_FILE_NAME = args.i
        META_FILE_NAME = args.m
        reference_genbank_name = args.gb
        OUTPUT_FOLDER = args.o
        REFERENCE_ID = args.r
        en_thres = args.e
        null_thres = args.n
        ISM_df = build_ISM(MSA_FILE_NAME, META_FILE_NAME, reference_genbank_name, OUTPUT_FOLDER, 
                   REFERENCE_ID, en_thres, null_thres)
        entropy_time_series_analysis(OUTPUT_FOLDER, OUTPUT_FOLDER, REFERENCE_ID)
    elif args.subparser_name == "ents":
        INPUT_FOLDER = args.i
        OUTPUT_FOLDER = args.o
        REFERENCE_ID = args.r
        entropy_time_series_analysis(INPUT_FOLDER, OUTPUT_FOLDER, REFERENCE_ID)
    elif args.subparser_name == "analyze":
        ISM_df_path = args.i
        OUTPUT_FOLDER = args.o
        ISM_df = pd.read_csv(ISM_df_path)
        ISM_df['date'] = pd.to_datetime(ISM_df['date'])
        region_raw_count, state_raw_count, count_dict = ISM_analysis(ISM_df, OUTPUT_FOLDER)
    elif args.subparser_name == "visualize":
        INPUT_FOLDER = args.i
        OUTPUT_FOLDER = args.o
        sampling_depth = args.sd
        REFERENCE_ID = 'EPI_ISL_402125'
        ISM_df = pd.read_csv('{}/ISM_df_with_correction.csv'.format(INPUT_FOLDER))
        ISM_df['date'] = pd.to_datetime(ISM_df['date'])
        with open('{}/region_pie_chart.json'.format(INPUT_FOLDER), 'r') as fp:
            region_raw_count = json.load(fp)
        with open('{}/state_pie_chart.json'.format(INPUT_FOLDER), 'r') as fp:
            state_raw_count = json.load(fp)
        with open('{}/region_time_series.json'.format(INPUT_FOLDER), 'r') as fp:
            count_dict = json.load(fp)
        region_list = ['Mainland China', 'Japan', 'South Korea', 'Hong Kong', 'India',
               'Australia', 'New Zealand', 'Brazil', 'USA', 'Canada', 
               'United Kingdom', 'Iceland', 'Belgium', 'Netherlands', 'Denmark',
               'France', 'Italy', 'Spain', 'Germany', 'Russia',
               ]

        state_list = [
                        'Washington','Oregon','California','Alaska','Idaho',
                        'Michigan','Wisconsin','Minnesota','Illinois','New Mexico', 
                        'Nebraska','Wyoming','Utah','Arizona','Texas',
                        'Massachusetts','Connecticut','New York','New Jersey','Pennsylvania',
                        'Maryland','Washington DC','Virginia','Florida','Louisiana',
                     ]

        time_series_region_list = ['Mainland China', 'Japan', 'USA', 'France', 'Denmark', 
                                   'United Kingdom', 'Netherlands', 'Australia', 'Canada', 'Spain']

        ISM_set, region_pie_chart, state_pie_chart, count_list, date_list = ISM_visualization(region_raw_count, state_raw_count, 
                                                                                              count_dict, region_list, 
                                                                                              state_list,
                                                                                              time_series_region_list,
                                                                                              OUTPUT_FOLDER,
                                                                                              ISM_FILTER_THRESHOLD=0.05,
                                                                                              ISM_TIME_SERIES_FILTER_THRESHOLD=0.025)
        REFERENCE_date = ISM_df[ISM_df['gisaid_epi_isl'] == REFERENCE_ID]['date'].min().date()
        region_pca_plot(INPUT_FOLDER, OUTPUT_FOLDER, sampling_depth)
        ISM_plot(ISM_df, ISM_set, region_list, region_pie_chart, state_list, state_pie_chart, REFERENCE_date, time_series_region_list, count_list, date_list, OUTPUT_FOLDER)   
        
    elif args.subparser_name == "default":
        MSA_FILE_NAME = args.i
        META_FILE_NAME = args.m
        OUTPUT_FOLDER = args.o
        reference_genbank_name = 'data/covid-19-genbank.gb'
        REFERENCE_ID = 'EPI_ISL_402125'
        en_thres = 0.2
        null_thres = 0.25
        ISM_df = build_ISM(MSA_FILE_NAME, META_FILE_NAME, reference_genbank_name, OUTPUT_FOLDER, 
                   REFERENCE_ID, en_thres, null_thres)
        entropy_time_series_analysis(OUTPUT_FOLDER, OUTPUT_FOLDER, REFERENCE_ID)
        region_raw_count, state_raw_count, count_dict = ISM_analysis(ISM_df, OUTPUT_FOLDER)
        
        region_list = ['Mainland China', 'Japan', 'Singapore', 'Hong Kong', 'India',
               'Australia', 'New Zealand', 'Brazil', 'USA', 'Canada', 
               'United Kingdom', 'Iceland', 'Belgium', 'Netherlands', 'Denmark',
               'France', 'Italy', 'Spain', 'Germany', 'Russia',
               ]

        state_list = [
                        'Washington','Oregon','California','Alaska','Idaho',
                        'Michigan','Wisconsin','Minnesota','Illinois','New Mexico', 
                        'Nebraska','Wyoming','Utah','Arizona','Texas',
                        'Massachusetts','Connecticut','New York','New Jersey','Pennsylvania',
                        'Maryland','Washington DC','Virginia','Florida','Louisiana',
                     ]

        time_series_region_list = ['Mainland China', 'Japan', 'USA', 'France', 'Denmark', 
                                   'United Kingdom', 'Netherlands', 'Australia', 'Canada', 'Spain']

        ISM_set, region_pie_chart, state_pie_chart, count_list, date_list = ISM_visualization(region_raw_count, state_raw_count, 
                                                                                              count_dict, region_list, 
                                                                                              state_list,
                                                                                              time_series_region_list,
                                                                                              OUTPUT_FOLDER,
                                                                                              ISM_FILTER_THRESHOLD=0.05,
                                                                                              ISM_TIME_SERIES_FILTER_THRESHOLD=0.025)
        REFERENCE_date = ISM_df[ISM_df['gisaid_epi_isl'] == REFERENCE_ID]['date'].min().date()
        region_pca_plot(OUTPUT_FOLDER, OUTPUT_FOLDER, sampling_depth = 150)
        ISM_plot(ISM_df, ISM_set, region_list, region_pie_chart, state_list, state_pie_chart, REFERENCE_date, time_series_region_list, count_list, date_list, OUTPUT_FOLDER)
    elif args.subparser_name == "compress":
        ISM_df_path = args.i
        annotation_df_path = args.a
        compressed_position_path = args.p
        OUTPUT_FOLDER = args.o
        
        ISM_df = pd.read_csv(ISM_df_path)
        ISM_df['date'] = pd.to_datetime(ISM_df['date'])
        annotation_df = pd.read_csv(annotation_df_path)
        pos = annotation_df['Ref position'].tolist()
        pos_to_idx = {pos[i]: i for i in range(len(pos))}
        with open(compressed_position_path) as f:
            compressed_list = [int(item) for item in f.read().split(',')]

        ISM_df['ISM_compressed'] = ISM_df.apply(lambda x, compressed_list=compressed_list, 
                              pos_dict=pos_to_idx: ''.join([x['ISM'][pos_dict[pos]] for pos in compressed_list]), 
                              axis = 1)
        ISM_df.to_csv('{}/ISM_df_compressed.csv'.format(OUTPUT_FOLDER), index=False)
        ISM_df['ISM'] = ISM_df['ISM_compressed']
        region_raw_count, state_raw_count, count_dict = ISM_analysis(ISM_df, OUTPUT_FOLDER)
    
    
if __name__ == "__main__":
    main()
